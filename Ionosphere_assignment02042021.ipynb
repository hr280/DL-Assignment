{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.4'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv('ionosphere_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the dataset \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.72873</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>0.68421</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.64407</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60194</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57619</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature21</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49909</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature22</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature23</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.53176</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature24</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature25</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55389</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature26</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>-0.01505</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature27</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>0.70824</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature28</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>-0.01769</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature29</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49664</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature30</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature31</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature32</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature33</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40956</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature34</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min       25%      50%       75%  max\n",
       "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
       "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
       "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
       "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
       "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
       "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
       "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
       "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
       "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
       "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
       "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
       "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
       "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
       "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
       "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
       "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
       "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
       "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
       "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
       "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
       "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
       "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
       "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
       "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
       "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
       "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
       "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
       "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
       "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
       "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
       "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
       "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
       "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
       "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)\n",
    "    print(len(df[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature3   351 non-null    float64\n",
      " 2   feature4   351 non-null    float64\n",
      " 3   feature5   351 non-null    float64\n",
      " 4   feature6   351 non-null    float64\n",
      " 5   feature7   351 non-null    float64\n",
      " 6   feature8   351 non-null    float64\n",
      " 7   feature9   351 non-null    float64\n",
      " 8   feature10  351 non-null    float64\n",
      " 9   feature11  351 non-null    float64\n",
      " 10  feature12  351 non-null    float64\n",
      " 11  feature13  351 non-null    float64\n",
      " 12  feature14  351 non-null    float64\n",
      " 13  feature15  351 non-null    float64\n",
      " 14  feature16  351 non-null    float64\n",
      " 15  feature17  351 non-null    float64\n",
      " 16  feature18  351 non-null    float64\n",
      " 17  feature19  351 non-null    float64\n",
      " 18  feature20  351 non-null    float64\n",
      " 19  feature21  351 non-null    float64\n",
      " 20  feature22  351 non-null    float64\n",
      " 21  feature23  351 non-null    float64\n",
      " 22  feature24  351 non-null    float64\n",
      " 23  feature25  351 non-null    float64\n",
      " 24  feature26  351 non-null    float64\n",
      " 25  feature27  351 non-null    float64\n",
      " 26  feature28  351 non-null    float64\n",
      " 27  feature29  351 non-null    float64\n",
      " 28  feature30  351 non-null    float64\n",
      " 29  feature31  351 non-null    float64\n",
      " 30  feature32  351 non-null    float64\n",
      " 31  feature33  351 non-null    float64\n",
      " 32  feature34  351 non-null    float64\n",
      " 33  label      351 non-null    object \n",
      "dtypes: float64(32), int64(1), object(1)\n",
      "memory usage: 93.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for feature in df:\\n    print(feature)\\n    df[feature].hist()\\n    plt.show()'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for feature in df:\n",
    "    print(feature)\n",
    "    df[feature].hist()\n",
    "    plt.show()'''\n",
    "\n",
    "# df.hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac= 0.6, random_state=125)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1]\n",
    "train_data = train_data.iloc[:,0:-1]\n",
    "test_label = test_data.iloc[:,-1]\n",
    "test_data = test_data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns= 'label', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>-0.00482</td>\n",
       "      <td>0.96683</td>\n",
       "      <td>-0.00722</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>-0.03923</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.02003</td>\n",
       "      <td>0.93772</td>\n",
       "      <td>-0.03034</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05843</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>-0.03464</td>\n",
       "      <td>0.92226</td>\n",
       "      <td>-0.03673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14754</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04918</td>\n",
       "      <td>0.57377</td>\n",
       "      <td>-0.01639</td>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.85246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31148</td>\n",
       "      <td>-0.34426</td>\n",
       "      <td>0.52385</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.32787</td>\n",
       "      <td>-0.03279</td>\n",
       "      <td>0.27869</td>\n",
       "      <td>-0.44262</td>\n",
       "      <td>0.49180</td>\n",
       "      <td>-0.06557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>0.19118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74265</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84557</td>\n",
       "      <td>-0.08580</td>\n",
       "      <td>-0.31745</td>\n",
       "      <td>-0.80553</td>\n",
       "      <td>-0.08961</td>\n",
       "      <td>-0.56435</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.04576</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78932</td>\n",
       "      <td>-0.03718</td>\n",
       "      <td>0.70882</td>\n",
       "      <td>-0.25288</td>\n",
       "      <td>0.77884</td>\n",
       "      <td>-0.14109</td>\n",
       "      <td>-0.21354</td>\n",
       "      <td>-0.78170</td>\n",
       "      <td>-0.18494</td>\n",
       "      <td>-0.59867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>-0.41912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "270         1   1.00000   0.08013   0.96775  -0.00482   0.96683  -0.00722   \n",
       "116         1   1.00000  -0.14754   1.00000   0.04918   0.57377  -0.01639   \n",
       "135         1   0.89706   0.38235   0.91176   0.37500   0.74265   0.67647   \n",
       "91          1   0.84557  -0.08580  -0.31745  -0.80553  -0.08961  -0.56435   \n",
       "100         1   1.00000  -1.00000   0.00000   0.00000   0.77941  -0.99265   \n",
       "\n",
       "     feature9  feature10  feature11  ...  feature25  feature26  feature27  \\\n",
       "270   0.87980   -0.03923    1.00000  ...    0.98164    0.02003    0.93772   \n",
       "116   0.65574    0.01639    0.85246  ...    0.31148   -0.34426    0.52385   \n",
       "135   0.45588    0.77941    0.19118  ...   -0.74265   -0.12500   -0.67925   \n",
       "91    0.80648    0.04576    0.89514  ...    0.78932   -0.03718    0.70882   \n",
       "100   0.80882    0.55147   -0.41912  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "270   -0.03034    1.00000   -0.05843    0.92774   -0.03464    0.92226   \n",
       "116   -0.20325    0.32787   -0.03279    0.27869   -0.44262    0.49180   \n",
       "135   -0.24131   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   \n",
       "91    -0.25288    0.77884   -0.14109   -0.21354   -0.78170   -0.18494   \n",
       "100   -1.00000    1.00000   -1.00000    1.00000   -1.00000    0.00000   \n",
       "\n",
       "     feature34  \n",
       "270   -0.03673  \n",
       "116   -0.06557  \n",
       "135   -0.56618  \n",
       "91    -0.59867  \n",
       "100    0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    1\n",
       "116    0\n",
       "135    1\n",
       "91     0\n",
       "100    0\n",
       "      ..\n",
       "213    1\n",
       "161    1\n",
       "141    1\n",
       "59     0\n",
       "113    1\n",
       "Name: label, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardized the Input Variables. **Hint**: Centeralized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the data\n",
    "# train_mean = train_data.mean()\n",
    "# train_data -= train_mean\n",
    "# train_std = train_data.std()\n",
    "# train_data /= train_std\n",
    "# test_data -= train_mean\n",
    "# test_data /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the data if needed.\n",
    "- Split into 60 and 40 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sample the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 33)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 33)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label.sum()/len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = np.array(train_set.as_matrix())\n",
    "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_label))\n",
    "print(type(test_data))\n",
    "print(type(test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print(test_label.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model : 1 hidden layers including 16 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                2176      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "11/11 [==============================] - 1s 35ms/step - loss: 0.5621 - accuracy: 0.7303 - val_loss: 0.4954 - val_accuracy: 0.7907\n",
      "Epoch 2/75\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5149 - accuracy: 0.7784 - val_loss: 0.4362 - val_accuracy: 0.7907\n",
      "Epoch 3/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.8053 - val_loss: 0.3924 - val_accuracy: 0.7907\n",
      "Epoch 4/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4248 - accuracy: 0.8225 - val_loss: 0.3585 - val_accuracy: 0.8837\n",
      "Epoch 5/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8248 - val_loss: 0.3313 - val_accuracy: 0.9070\n",
      "Epoch 6/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3809 - accuracy: 0.9096 - val_loss: 0.3086 - val_accuracy: 0.9767\n",
      "Epoch 7/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3667 - accuracy: 0.9065 - val_loss: 0.2664 - val_accuracy: 0.9535\n",
      "Epoch 8/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3095 - accuracy: 0.9033 - val_loss: 0.2368 - val_accuracy: 0.9767\n",
      "Epoch 9/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.2891 - accuracy: 0.9326 - val_loss: 0.2106 - val_accuracy: 0.9767\n",
      "Epoch 10/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2634 - accuracy: 0.9405 - val_loss: 0.1882 - val_accuracy: 0.9767\n",
      "Epoch 11/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3147 - accuracy: 0.8986 - val_loss: 0.1722 - val_accuracy: 0.9767\n",
      "Epoch 12/75\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2519 - accuracy: 0.9222 - val_loss: 0.1568 - val_accuracy: 0.9767\n",
      "Epoch 13/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2252 - accuracy: 0.9438 - val_loss: 0.1527 - val_accuracy: 0.9767\n",
      "Epoch 14/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1969 - accuracy: 0.9461 - val_loss: 0.1374 - val_accuracy: 0.9767\n",
      "Epoch 15/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1642 - accuracy: 0.9469 - val_loss: 0.1289 - val_accuracy: 0.9767\n",
      "Epoch 16/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9664 - val_loss: 0.1197 - val_accuracy: 0.9767\n",
      "Epoch 17/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.9676 - val_loss: 0.1163 - val_accuracy: 0.9767\n",
      "Epoch 18/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1451 - accuracy: 0.9627 - val_loss: 0.1091 - val_accuracy: 0.9767\n",
      "Epoch 19/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1607 - accuracy: 0.9491 - val_loss: 0.1092 - val_accuracy: 0.9767\n",
      "Epoch 20/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1218 - accuracy: 0.9796 - val_loss: 0.0981 - val_accuracy: 0.9767\n",
      "Epoch 21/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1321 - accuracy: 0.9493 - val_loss: 0.0959 - val_accuracy: 0.9767\n",
      "Epoch 22/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1164 - accuracy: 0.9694 - val_loss: 0.0952 - val_accuracy: 0.9767\n",
      "Epoch 23/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1098 - accuracy: 0.9730 - val_loss: 0.0901 - val_accuracy: 0.9767\n",
      "Epoch 24/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1242 - accuracy: 0.9560 - val_loss: 0.0875 - val_accuracy: 0.9767\n",
      "Epoch 25/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1118 - accuracy: 0.9726 - val_loss: 0.0855 - val_accuracy: 0.9767\n",
      "Epoch 26/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0878 - accuracy: 0.9871 - val_loss: 0.0897 - val_accuracy: 0.9767\n",
      "Epoch 27/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9452 - val_loss: 0.0877 - val_accuracy: 0.9767\n",
      "Epoch 28/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 0.9798 - val_loss: 0.0913 - val_accuracy: 0.9767\n",
      "Epoch 29/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1178 - accuracy: 0.9645 - val_loss: 0.0812 - val_accuracy: 0.9767\n",
      "Epoch 30/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1108 - accuracy: 0.9617 - val_loss: 0.0771 - val_accuracy: 0.9767\n",
      "Epoch 31/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0658 - accuracy: 0.9838 - val_loss: 0.0830 - val_accuracy: 0.9767\n",
      "Epoch 32/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0590 - accuracy: 0.9916 - val_loss: 0.0790 - val_accuracy: 0.9767\n",
      "Epoch 33/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9606 - val_loss: 0.0989 - val_accuracy: 0.9767\n",
      "Epoch 34/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 0.9848 - val_loss: 0.0893 - val_accuracy: 0.9767\n",
      "Epoch 35/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9914 - val_loss: 0.0807 - val_accuracy: 0.9767\n",
      "Epoch 36/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0892 - accuracy: 0.9639 - val_loss: 0.0665 - val_accuracy: 0.9767\n",
      "Epoch 37/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.9805 - val_loss: 0.0754 - val_accuracy: 0.9767\n",
      "Epoch 38/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 0.9796 - val_loss: 0.0618 - val_accuracy: 0.9767\n",
      "Epoch 39/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9924 - val_loss: 0.0541 - val_accuracy: 0.9767\n",
      "Epoch 40/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9758 - val_loss: 0.0606 - val_accuracy: 0.9767\n",
      "Epoch 41/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9973 - val_loss: 0.0573 - val_accuracy: 0.9767\n",
      "Epoch 42/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0412 - accuracy: 0.9901 - val_loss: 0.0659 - val_accuracy: 0.9767\n",
      "Epoch 43/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0423 - accuracy: 0.9902 - val_loss: 0.0443 - val_accuracy: 0.9767\n",
      "Epoch 44/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0571 - accuracy: 0.9827 - val_loss: 0.0459 - val_accuracy: 0.9767\n",
      "Epoch 45/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9817 - val_loss: 0.0433 - val_accuracy: 0.9767\n",
      "Epoch 46/75\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0541 - accuracy: 0.9888 - val_loss: 0.0481 - val_accuracy: 0.9767\n",
      "Epoch 47/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0476 - accuracy: 0.9973 - val_loss: 0.0573 - val_accuracy: 0.9767\n",
      "Epoch 48/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 0.9790 - val_loss: 0.0392 - val_accuracy: 0.9767\n",
      "Epoch 49/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 50/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9838 - val_loss: 0.0454 - val_accuracy: 0.9767\n",
      "Epoch 51/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0876 - accuracy: 0.9710 - val_loss: 0.0355 - val_accuracy: 0.9767\n",
      "Epoch 52/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9840 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9805 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 54/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 55/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9817 - val_loss: 0.0351 - val_accuracy: 0.9767\n",
      "Epoch 56/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9946 - val_loss: 0.0247 - val_accuracy: 0.9767\n",
      "Epoch 57/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9838 - val_loss: 0.0380 - val_accuracy: 0.9767\n",
      "Epoch 58/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9944 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 59/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 60/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 61/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9916 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 62/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 63/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 65/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9985 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 66/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0388 - accuracy: 0.9771 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 67/75\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 69/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 70/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 71/75\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 0.9916 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 72/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 73/75\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9888 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 74/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 75/75\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.2, epochs=75, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(75)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx00lEQVR4nO3deZxU1Z338c+PZhNBZHWhgUbFBV/K1mLEaDQaxWUw+OgE7DEQkwdFjdEZ42gw0ag8j06c0XFckvZxC6K4JQ5mNAjuiYnSKiCiKCoIKNiyCTY7v+ePewtuV9/qrqqu6qru/r5fr3pV3XPPvfdXVVC/Pufce665OyIiIsnaFDoAEREpTkoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUICRtZvacmY3Pdd1CMrMlZnZyHvbrZnZQ+Pq3ZvbLdOpmcZwKM3s+2zhF6mO6DqJlM7ONkcVOwBZgR7h8obtPa/qoioeZLQF+4u6zc7xfBwa6++Jc1TWzMuBToJ27b89JoCL1aFvoACS/3L1z4nV9P4Zm1lY/OlIs9O+xOKiLqZUysxPMbLmZ/auZrQQeMLNuZvYnM6s2s7Xh69LINi+b2U/C1xPM7C9mdmtY91MzOy3LugPM7FUz22Bms83sLjN7OEXc6cR4o5n9Ndzf82bWM7L+fDNbamarzWxyPZ/P0Wa20sxKImVjzGx++HqEmf3NzNaZ2RdmdqeZtU+xrwfN7KbI8s/DbT43swuS6p5hZu+Y2ddmtszMro+sfjV8XmdmG83smMRnG9l+pJnNMbP14fPIdD+bDD/n7mb2QPge1prZ05F1Z5nZ3PA9fGxmo8LyWt15ZnZ94ns2s7Kwq+3HZvYZ8GJY/kT4PawP/40cHtl+DzP79/D7XB/+G9vDzP7HzH6a9H7mm9mYuPcqqSlBtG77At2B/sBEgn8PD4TL/YBNwJ31bH80sAjoCfwbcJ+ZWRZ1HwHeBHoA1wPn13PMdGI8D/gR0BtoD1wJYGaDgHvC/e8fHq+UGO7+BvAN8N2k/T4Svt4BXBG+n2OAk4CL64mbMIZRYTzfAwYCyeMf3wA/BPYGzgAmmdn3w3XHh897u3tnd/9b0r67A/8D3BG+t/8A/sfMeiS9hzqfTYyGPuepBF2Wh4f7ui2MYQTwe+Dn4Xs4HliS4hhxvgMcBpwaLj9H8Dn1Bt4Gol2itwLDgZEE/46vAnYCDwH/lKhkZoOBPgSfjWTC3fVoJQ+C/6gnh69PALYCHeupPwRYG1l+maCLCmACsDiyrhPgwL6Z1CX48dkOdIqsfxh4OM33FBfjtZHli4E/h69/BUyPrNsz/AxOTrHvm4D7w9ddCH68+6eoeznwx8iyAweFrx8Ebgpf3w/cHKl3cLRuzH5vB24LX5eFddtG1k8A/hK+Ph94M2n7vwETGvpsMvmcgf0Ifoi7xdT7XSLe+v79hcvXJ77nyHs7oJ4Y9g7rdCVIYJuAwTH1OgJrCcZ1IEgkd+fj/1RLf6gF0bpVu/vmxIKZdTKz34VN9q8JujT2jnazJFmZeOHuNeHLzhnW3R9YEykDWJYq4DRjXBl5XROJaf/ovt39G2B1qmMRtBbONrMOwNnA2+6+NIzj4LDbZWUYx/8haE00pFYMwNKk93e0mb0Udu2sBy5Kc7+JfS9NKltK8NdzQqrPppYGPue+BN/Z2phN+wIfpxlvnF2fjZmVmNnNYTfV1+xuifQMHx3jjhX+m34M+CczawOMI2jxSIaUIFq35FPY/gU4BDja3fdid5dGqm6jXPgC6G5mnSJlfeup35gYv4juOzxmj1SV3X0hwQ/sadTuXoKgq+oDgr9S9wJ+kU0MBC2oqEeAGUBfd+8K/Day34ZOOfycoEsoqh+wIo24ktX3OS8j+M72jtluGXBgin1+Q9B6TNg3pk70PZ4HnEXQDdeVoJWRiOErYHM9x3oIqCDo+qvxpO44SY8ShER1IWi2rwv7s6/L9wHDv8irgOvNrL2ZHQP8Q55ifBI408y+HQ4o30DD/wceAX5G8AP5RFIcXwMbzexQYFKaMTwOTDCzQWGCSo6/C8Ff55vD/vzzIuuqCbp2Dkix72eBg83sPDNra2Y/AAYBf0oztuQ4Yj9nd/+CYGzg7nAwu52ZJRLIfcCPzOwkM2tjZn3CzwdgLjA2rF8OnJNGDFsIWnmdCFppiRh2EnTX/YeZ7R+2No4JW3uECWEn8O+o9ZA1JQiJuh3Yg+Cvs78Df26i41YQDPSuJuj3f4zghyHO7WQZo7u/B1xC8KP/BUE/9fIGNnuUYOD0RXf/KlJ+JcGP9wbg3jDmdGJ4LnwPLwKLw+eoi4EbzGwDwZjJ45Fta4ApwF8tOHvqW0n7Xg2cSfDX/2qCQdszk+JO1+3U/zmfD2wjaEV9STAGg7u/STAIfhuwHniF3a2aXxL8xb8W+DW1W2Rxfk/QglsBLAzjiLoSeBeYA6wBbqH2b9rvgSMIxrQkC7pQToqOmT0GfODueW/BSMtlZj8EJrr7twsdS3OlFoQUnJkdZWYHhl0Sowj6nZ8ucFjSjIXddxcDlYWOpTlTgpBisC/BKZgbCc7hn+Tu7xQ0Imm2zOxUgvGaVTTcjSX1UBeTiIjEUgtCRERitZjJ+nr27OllZWWFDkNEpFl56623vnL3XnHrWkyCKCsro6qqqtBhiIg0K2aWfPX9LupiEhGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmVtwRhZveb2ZdmtiDFejOzO8xscXg7wGGRdePN7KPwMT5fMYpI6zVtGpSVQZs2wfO0aQ1tkdn+Lr448/03FFMujpGRfN2JiGB65GHAghTrTyeYMtiAbwFvhOXdgU/C527h6zp3rkp+DB8+3EVE0vHww+6dOrnD7kenTkF5rvaX/Gho/w3FlItjxAGqPMXvat6ug3D3V82srJ4qZwG/DwP8u5ntbWb7EdwKc5a7rwEws1nAKIJpl0WkCcyfD9XVcNJJ6dXfsAH+679g8+bUddq1gwsvhN69s4tp7lz4wx+y2zbZHXdATU3tspoauOQSWLQoN/tL1tD+G4op3WNMngwVFenHXp9CXijXh9q3XlwelqUqr8PMJgITAfr1S74xl4hk69JL4d134auvoCTVDWcjfv/74IcJwFLcV88dtm2DG27ILqZ//md46aXU+89Eqino1q+Hm27K3f4y2X9DMaV7jM8+S69eOpr1ILW7V7p7ubuX9+oVe6W4SLOS637xbI5x773w2muwbh2UlqbXzz1zJhxwQPAjtnNn/ONb3wrqpRNT8jHvuw/+8hf4+c+DfU2dCom/Cfv1C5ajx2poff/kG7OG+vdPfx/R9ekk0Wi9xP7S2UciplQxJ8vp38qp+p5y8SC4h2yqMYjfAeMiy4uA/QhuMP67VPVSPTQGIc1drvvFsznGww+7t2+fWT/3li3unTu7T5pU/7Gvu87dzP2rrxqOKfnRoUPwPHt2dn31yTE3dh/pxNzQo127zD7rQoxBFDJBnEHtQeo3w/LuwKcEA9TdwtfdGzqWEoQ0d/37x/+n79+/6Y6Ran19Mb30UlD29NP1H/v114N606enF1Pyw8x98+bs30Py5/jww0GZWfAc/WHN9hglJbv3N2nS7v2XlKSfOKL7SP6xT445eoy4+umoL0Hk7X4QZvYowYBzT4Ibd1wHtAtbLb81MwPuJBiArgF+5O5V4bYXAL8IdzXF3R9o6Hjl5eWuyfqkOWvTJr6f2SzoYmiKY6Tbvx+N6Zpr4NZbYfVq2Guv1Nts3w69esGYMXD//Q3HFMe94feQi88x18fI5D3m8vtO73j2lruXx63L2xiEu49z9/3cvZ27l7r7fe7+W3f/bbje3f0Sdz/Q3Y9IJIdw3f3uflD4aDA5iBSLxowhpOo7jpans//6+vPbpPgfnzjG/vtnHuvMmTByZO3kEBdn27Zw8slB/YcfbjimZGb110+sS7W+e/f0rzHI9hjpfIcNyfT7zqtUTYvm9lAXkxRaY8cQ8tW33tAjuo8f/jCz+itXBmU33ZTe+6isDJY7dswsxsY+4vr7cz2mUN93Hbf/bGLK9ZiUu9fbxVTwH/ZcPZQgpNByMYbQmH7x+uqk28995pnuvXvvjmGPPYIB6H794utPnRrsb86c9OJcujS9mKJ96w3VT9W/H91fjx71f3YNjSmkc4yGfrjjvtvGft+5UF+CaDH3pNYYhBRavscQ0tl/un3dcTFt3Rp0w/zwh3D33UHZ734HF10ECxfCYYfV3c/558Of/wyrVu3udsl2nCMupm3boH37+us35nNJdx9NMT6UrKmOWZAxCJHGKIbrATLdJpv+50zm3kmnbz3d/vy4mP76V/jmGzj11N1lidfR6xcSMZnBI4/AwIG1j5vq/SbiS5Ug4rb7+98bfg/pfO4N1Wns+nwoxDHrSNW0aG4PdTG1HMVwPUA222S6z1yca5/OufTp9pVffbV727bu69fXLj/4YPfTTksdU/v2uR0Hibr2Wvc2bYKursZ87vm47iEf4wFRGoNQgpAYxXA9QLbb1NennOn+0jnXPlXfeqr+/PpiGjrU/fjj65b/9KfBD/SmTdldY5Cq/96s4ZiOOsp95MiGP9d0PvfG7iOT7zZXmuKYShBSr2z+Eeb6H250f6n+yjRrXEzpHCNxnLgf1mziqu/Cpob2l6pO9Hjp1Ennsy8tDbbbe++6n9uf/hSsmzWr4bjjPvf6tqlPdXWw7a9/nf57kcwpQUhK+ehqyUUMmf513xRTI6T6oUsVV7bHzOSK4Ma2ttL5LjduDLqRrrwyvbOkkrevb5vPPksd26OPBnX+/vf03otkp74EobOY8mD+/GBQ7+c/j19fXQ1XXQWbNjVtXHGeeSZ+CuFOneAf/iF322QTQ1RJCRx1VOoJyxqKKZ1jZKO+uLI5ZnR/S5fCnDmwY0fq46VTpz6pYuzfH5Ys2b180kmwYEEwIV/y8eJEt582DSZOrH2cjh2DqcGPOy71xXnz5gVnR1VXpz8ZnmSuvrOYCjndd4v1wANw++1w7rnB2R7JHnkEHnwQDj44N1MXN0aqH7CammD+/Vxtk00MCW3bBlM0rF0bPLKJKZfJoW3bYNqIhuLK9Jhx++vdO/iBrO946dRJJVWMyVNGT5oEv/xlsM/o8VKJbp+4N8HkyUF5v37B9NVPPgkffABffpl6P5dfruRQUKmaFs3tUUxdTGPHBk3j3/42fv1ppwVnhhSD5jBYm4v3kY9J6rKNqTH7zLXGfvZNdTGX5A/1dDHpOog8WLUqeI6b+37zZnj5ZTjllCYNKaUpU4JumKhOnYLybLdJdCksXRr8XCxdGiynus4gmxgy3Uc265PlIqbG7jPXGvvZ5+K7kyKWKnM0t0cxtSAOOyz4K2qvvdy3bq29btasYN0zzxQmtji5Pospm78qc3FWVK5PY8zFVMr52GeuNfazL8Tpn5I7aJC6afXoAR06wBdfBHfBOvbY3euuuioYn1izBjp3LliIeVWIaQlEJDuaaqMJbdkS/PiPHRv8UCZ3M82cCd/+dstNDtDwVAu5mjojk2kqimm6DpFmI1XTork9iqWL6bPPgu6Uykr3Y45xHzFi97rPPw/W3Xxz4eJrCvm6NWJDx2jqqREKMf2CSK6hQeqmkxig3mefYKKzOXOCO20BPP988BydDK0lqqiAysrgXHiz+NMUa2qC0x6zNXly3VM0o/tsaH0uNMUxRApJCSLHVq4MnvfdN0gE7jB7dlA2c2aQOI48snDxNZWKiuBCqZ07U487JJ9rn4lU2ybKG1qfC01xDJFCUoLIsWiCOOoo6NYtSAw7d8KsWcHprelOyVxM8n0rzUxjaOiWj00xVXJRTMcskkfN8KequCW6mHr3DrpWEvfgfftt+Oqr5tm9lOl1Dclyca58cgxxUz1kct1DLugaAGnxUg1ONLdHsQxSX3ppMCNmwr33BoOX48YFz6tWFS62bOX7VpqNiaG+Wz42xfn5ugZAmjt0HUTTOffcYFKz998Plpct293lMHRo0JJoborhuoZiiEGkJdJ1EE1o1apgIDqhb9/d9/Jtjt1LkF5fe6ZjFJnWV3+/SNPLa4Iws1FmtsjMFpvZ1THr+5vZC2Y238xeNrPSyLodZjY3fMzIZ5y5tHJlMEAdlUgMzTVB5HrupWzGNNTfL1IAqfqeGvsASoCPgQOA9sA8YFBSnSeA8eHr7wJTI+s2ZnK8YhmD6NLF/bLLapd9+KH7z35Wd16m5iSXcy9lO6ah/n6R3KNAF8qNABa7+yfuvhWYDpyVVGcQ8GL4+qWY9c1KTQ1s2FC3BTFwYDD/Urt2BQmrjnS6d5LrwO7rGpYs2T3HP2R+PUC21w9Er61IjkFEci+fCaIPsCyyvDwsi5oHnB2+HgN0MbMe4XJHM6sys7+b2ffjDmBmE8M6VdXV1TkMPTuJU1yTE0QxSad7J9MuoEzHBzSeINI8FHqQ+krgO2b2DvAdYAWQOMO9vwcj6+cBt5vZgckbu3ulu5e7e3mvXr2aLOhUotNsFKt0pofIdAqJTMcHNJ4g0jzkM0GsAPpGlkvDsl3c/XN3P9vdhwKTw7J14fOK8PkT4GVgaB5jzYnoVdTFKp3unUy7gJLnXurfP1hO1QWUaX0RKYx83pN6DjDQzAYQJIaxBK2BXcysJ7DG3XcC1wD3h+XdgBp33xLWORb4tzzGmhPNIUH06xd0GcWVZ1InWUVFZj/wmdYXkaaXtxaEu28HLgVmAu8Dj7v7e2Z2g5mNDqudACwysw+BfYBEJ8NhQJWZzSMYvL7Z3RfmK9ZcSXQxFUFvV0rpdO+oC0hEIL8tCNz9WeDZpLJfRV4/CTwZs93rwBH5jC0fVq6Enj2L52ylOIm/2idPDrqM+vULfvijf82nU0dEWj5NtZFDY8bA4sXw7rsFDUNEJG2aaqOJJE+z0VR020sRyQcliByKm2Yj3xo7FbeISCpKEDniXpgEodteiki+KEHkyMaNsGlT03cx6baXIpIvShA50pTXQGRy683k+hqjEJF05fU019YkkSDy3YJIjDkkupUauvVmcv3EGAXotFURqZ9aEDnSVBP1xY05QHD/67hpKzRGISLZUgsiR5qqiynV2MLOnfG33tQYhYhkSy2IHFm5Mujj79Gj4brJkscILr449ZiBptYWkaaiBJEjq1ZB795BV08m4q5juOee1Nc1aGptEWkqShA5ku01EKnGFKKiYwaaWltEmooSRI5kO81GumMBS5emd/tPyOx2oSIiqShB5Ei2LYhMxgLSmUpDU2+ISK4oQeSAe9CCyCZBxI0RNKS+01R1WquI5IoSRA6sWwdbt2bXxRQ3RjBp0u7lVDI9fVWntYpIppQgcqC+ayDSmeaioqL2GMHdd+9e7t8//pg6rVVE8k0JIgdSJYhcjAfotFYRKRQliBxITLOR3MWUi/EAndYqIoWiqTZyIFULIlfjARUVmf3AZ1pfRCSOWhA5sHIltGsH3brVLtd4gIg0Z0oQObBsWdB6SD7rSOMBItKcKUE0kju8/DJ861t112k8QESas7wmCDMbZWaLzGyxmV0ds76/mb1gZvPN7GUzK42sG29mH4WP8fmMszEWLIDPP4dTT41fn3wKq5KDiDQXeUsQZlYC3AWcBgwCxpnZoKRqtwK/d/cjgRuA/xtu2x24DjgaGAFcZ2ZJPfzF4fnng+dUCUJEpLnKZwtiBLDY3T9x963AdOCspDqDgBfD1y9F1p8KzHL3Ne6+FpgFjMpjrFmbORMGDYLS0obriog0J/lMEH2AZZHl5WFZ1Dzg7PD1GKCLmfVIc1vMbKKZVZlZVXV1dc4CT1dNDbz6qloPItIyFXqQ+krgO2b2DvAdYAWwI92N3b3S3cvdvbxXr175ijGlV1+FLVuUIESkZcpnglgB9I0sl4Zlu7j75+5+trsPBSaHZevS2bYYzJwJHTrA8cenv006czOJiBSDfCaIOcBAMxtgZu2BscCMaAUz62lmiRiuAe4PX88ETjGzbuHg9ClhWVGZOTNIDnvskV593atBRJqTvCUId98OXErww/4+8Li7v2dmN5jZ6LDaCcAiM/sQ2AeYEm67BriRIMnMAW4Iy4rGsmXw/vuZdS/pXg0i0pzkdQzC3Z9194Pd/UB3T/z4/8rdZ4Svn3T3gWGdn7j7lsi297v7QeHjgXzGmY1Up7fW14WkezWISHNS6EHqZmvmTOjTBw4/fHdZQ11ImptJRJoTJYgs7NgBs2fDKafUnn+poS4kzc0kIs2JEkQW5syBtWvrdi811IWkuZlEpDnR/SCyMHNm8AN/8sm1y/v1C7qVkkW7kHSvBhFpLtSCyMJf/gJDh0KPHrXL1YUkIi2JEkQWvvwS+vatW64uJBFpSdTFlIU1a2D48Ph16kISkZZCLYgsrFlT9/aiIiItjRJEhrZsCU5d7d690JGIiOSXEkSG1q4NnpUgRKSlU4LI0JpwRih1MYlIS6cEkSG1IESktVCCyFCiBaEEISItnRJEhpQgRKS1UILIkMYgRKS1UILI0Nq1wVXSXbsWOhIRkfxSgshQ4iK5NvrkRKSF089chtas0fiDiLQOShAZWrtW4w8i0jooQWRILQgRaS2UIDKkBCEirUVaCcLM9jSzNuHrg81stJm1y29oxUkzuYpIa5FuC+JVoKOZ9QGeB84HHsxXUMVq505Yt04tCBFpHdJNEObuNcDZwN3ufi5weIMbmY0ys0VmttjMro5Z38/MXjKzd8xsvpmdHpaXmdkmM5sbPn6byZvKl6+/DpKEEoSItAbp3lHOzOwYoAL4cVhW0sAGJcBdwPeA5cAcM5vh7gsj1a4FHnf3e8xsEPAsUBau+9jdh6QZX5PQNBsi0pqk24K4HLgG+KO7v2dmBwAvNbDNCGCxu3/i7luB6cBZSXUc2Ct83RX4PM14CiIxk6vGIESkNUgrQbj7K+4+2t1vCQerv3L3yxrYrA+wLLK8PCyLuh74JzNbTtB6+Glk3YCw6+kVMzsu7gBmNtHMqsysqrq6Op230ihxLYhp06CsLLiyuqwsWBYRaQnSPYvpETPby8z2BBYAC83s5zk4/jjgQXcvBU4HpoYJ6Augn7sPBf4ZeMTM9kre2N0r3b3c3ct79eqVg3Dql5wgpk2DiRNh6VJwD54nTlSSEJGWId0upkHu/jXwfeA5YADBmUz1WQH0jSyXhmVRPwYeB3D3vwEdgZ7uvsXdV4flbwEfAwenGWveJCeIyZOD+1NH1dQE5SIizV26CaJdeN3D94EZ7r6NYPygPnOAgWY2wMzaA2OBGUl1PgNOAjCzwwgSRLWZ9QoHuQnHOwYCn6QZa94kj0F89ll8vVTlIiLNSboJ4nfAEmBP4FUz6w98Xd8G7r4duBSYCbxPcLbSe2Z2g5mNDqv9C/C/zWwe8Cgwwd0dOB6Yb2ZzgSeBi9x9TUbvLA/WrIFOnaBDh2C5X7/4eqnKRUSaEwt+j7PY0KxtmASKQnl5uVdVVeX1GBdcALNmwbJw6D0xBhHtZurUCSoroaIir6GIiOSEmb3l7uVx69IdpO5qZv+ROGPIzP6doDXRqqxdW/sMpoqKIBn07x/cRKh/fyUHEWk50r1Q7n6Cs5f+MVw+H3iA4MrqViNuHqaKCiUEEWmZ0k0QB7r7/4os/zocH2hV1qyBgQMLHYWISNNId5B6k5l9O7FgZscCm/ITUvHSVN8i0pqk24K4CPi9mXUNl9cC4/MTUvHS3eREpDVJd6qNee4+GDgSODK8wvm7eY2sSCSm0jCDTZt0jYOItB4Z3VHO3b8Or6iGYAqMFi06lUbCH/+oqTREpHVozC1HLWdRFKm4qTS2bdNUGiLSOjQmQWR3hV0zoqk0RKQ1q3eQ2sw2EJ8IDNgjLxEVkX79ancvRctFRFq6elsQ7t7F3feKeXRx93TPgGq2pkwJps6I6tgxKBcRaeka08XU4kWn0ki44w5dOS0irYMSRAMqKmDJkmBguqQEfvKTQkckItI0lCDSlJiHyVr8uVsiIgEliDRpmg0RaW2UINKkaTZEpLVRgkiTWhAi0tooQaQpkSASczO1aRM8a9oNEWmpWvy1DLmydi1UV9e+xejSpcEy6NRXEWl51IJIw44dsG4dvPFG3bmZamo0N5OItExKEGlYvx7cg+c4mptJRFoiJYg0rFkTPPfoEb9eczOJSEukBJGGtWuD5wkT6s7N1KmT5mYSkZYprwnCzEaZ2SIzW2xmV8es72dmL5nZO2Y238xOj6y7JtxukZmdms84G5JoQZx99u65mcyC58pKDVCLSMuUt7OYzKwEuAv4HrAcmGNmM9x9YaTatcDj7n6PmQ0CngXKwtdjgcOB/YHZZnawu+/IV7z1SSSI7t1h5EglBBFpHfLZghgBLHb3T9x9KzAdOCupjgN7ha+7Ap+Hr88Cprv7Fnf/FFgc7q8gEl1MulBORFqTfCaIPsCyyPLysCzqeuCfzGw5Qevhpxlsi5lNNLMqM6uqrq7OVdx1JFoQmmpDRFqTQg9SjwMedPdS4HRgqpmlHZO7V7p7ubuX9+rVK29BrlkDnTtDu3Z5O4SISNHJ55XUK4C+keXSsCzqx8AoAHf/m5l1BHqmuW2T0TxMItIa5bMFMQcYaGYDzKw9waDzjKQ6nwEnAZjZYUBHoDqsN9bMOpjZAGAg8GYeY63X2rVKECLS+uStBeHu283sUmAmUALc7+7vmdkNQJW7zwD+BbjXzK4gGLCe4O4OvGdmjwMLge3AJYU6gwl23yxIRKQ1seD3uPkrLy/3qqqqjLdbswaOPbb+Op9+CmecAU89lWVwIiJFyszecvfyuHWtfjbXtm3hyCPrr3PkkboXtYi0Pq0+Qey1Fzz2WKGjEBEpPoU+zVVERIqUEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBJJk2DcrKoE2b4HnatEJHJCJSGK1+uu+oadNg4kSoqQmWly4NlgEqKgoXl4hIIagFETF58u7kkFBTE5SLiLQ2ShARn32WWbmISEumBBHRr19m5SIiLZkSRMSUKdCpU+2yTp2CchGR1kYJIqKiAioroX9/MAueKys1QC0irZPOYkpSUaGEICICeW5BmNkoM1tkZovN7OqY9beZ2dzw8aGZrYus2xFZNyOfcYqISF15a0GYWQlwF/A9YDkwx8xmuPvCRB13vyJS/6fA0MguNrn7kHzFJyIi9ctnC2IEsNjdP3H3rcB04Kx66o8DHs1jPCIikoF8Jog+wLLI8vKwrA4z6w8MAF6MFHc0syoz+7uZfT/FdhPDOlXV1dU5CltERKB4zmIaCzzp7jsiZf3dvRw4D7jdzA5M3sjdK9293N3Le/Xq1VSxioi0CvlMECuAvpHl0rAszliSupfcfUX4/AnwMrXHJ0REJM/ymSDmAAPNbICZtSdIAnXORjKzQ4FuwN8iZd3MrEP4uidwLLAweVsREcmfvJ3F5O7bzexSYCZQAtzv7u+Z2Q1AlbsnksVYYLq7e2Tzw4DfmdlOgiR2c/TsJxERyT+r/bvcfJWXl3tVVVWhwxARaVbM7K1wvLeOYhmkFhGRIqMEISIisZQgREQklhKEiIjE0myuItJo27ZtY/ny5WzevLnQoUgKHTt2pLS0lHbt2qW9jRKEiDTa8uXL6dKlC2VlZZhZocORJO7O6tWrWb58OQMGDEh7O3UxiUijbd68mR49eig5FCkzo0ePHhm38JQgRCQnlByKWzbfjxKEiIjEUoIQkSY3bRqUlUGbNsHztGmN29/q1asZMmQIQ4YMYd9996VPnz67lrdu3VrvtlVVVVx22WUNHmPkyJGNC7IZ0iC1iDSpadNg4kSoqQmWly4NliH7+8H36NGDuXPnAnD99dfTuXNnrrzyyl3rt2/fTtu28T935eXllJfHzjRRy+uvv55dcM2YWhAi0qQmT96dHBJqaoLyXJowYQIXXXQRRx99NFdddRVvvvkmxxxzDEOHDmXkyJEsWrQIgJdffpkzzzwTCJLLBRdcwAknnMABBxzAHXfcsWt/nTt33lX/hBNO4JxzzuHQQw+loqKCxJx2zz77LIceeijDhw/nsssu27XfqCVLlnDccccxbNgwhg0bVivx3HLLLRxxxBEMHjyYq6++GoDFixdz8sknM3jwYIYNG8bHH3+c2w+qHmpBiEiT+uyzzMobY/ny5bz++uuUlJTw9ddf89prr9G2bVtmz57NL37xC5566qk623zwwQe89NJLbNiwgUMOOYRJkybVuXbgnXfe4b333mP//ffn2GOP5a9//Svl5eVceOGFvPrqqwwYMIBx48bFxtS7d29mzZpFx44d+eijjxg3bhxVVVU899xz/Pd//zdvvPEGnTp1Ys2aNQBUVFRw9dVXM2bMGDZv3szOnTtz/0GloAQhIk2qX7+gWymuPNfOPfdcSkpKAFi/fj3jx4/no48+wszYtm1b7DZnnHEGHTp0oEOHDvTu3ZtVq1ZRWlpaq86IESN2lQ0ZMoQlS5bQuXNnDjjggF3XGYwbN47Kyso6+9+2bRuXXnopc+fOpaSkhA8//BCA2bNn86Mf/YhOnToB0L17dzZs2MCKFSsYM2YMEFzs1pTUxSQiTWrKFAh/A3fp1Ckoz7U999xz1+tf/vKXnHjiiSxYsIBnnnkm5TUBHTp02PW6pKSE7du3Z1Unldtuu4199tmHefPmUVVV1eAgeiEpQYhIk6qogMpK6N8fzILnysrsB6jTtX79evr06QPAgw8+mPP9H3LIIXzyyScsWbIEgMceeyxlHPvttx9t2rRh6tSp7NixA4Dvfe97PPDAA9SEAzRr1qyhS5culJaW8vTTTwOwZcuWXeubghKEiDS5igpYsgR27gye850cAK666iquueYahg4dmtFf/OnaY489uPvuuxk1ahTDhw+nS5cudO3atU69iy++mIceeojBgwfzwQcf7GrljBo1itGjR1NeXs6QIUO49dZbAZg6dSp33HEHRx55JCNHjmTlypU5jz0V3VFORBrt/fff57DDDit0GAW3ceNGOnfujLtzySWXMHDgQK644opCh7VL3PekO8qJiDSBe++9lyFDhnD44Yezfv16LrzwwkKH1Cg6i0lEJEeuuOKKomoxNJZaECIiEksJQkREYilBiIhIrLwmCDMbZWaLzGyxmV0ds/42M5sbPj40s3WRdePN7KPwMT6fcYqISF15SxBmVgLcBZwGDALGmdmgaB13v8Ldh7j7EOC/gD+E23YHrgOOBkYA15lZt3zFKiLN24knnsjMmTNrld1+++1MmjQp5TYnnHACiVPjTz/9dNatW1enzvXXX7/reoRUnn76aRYuXLhr+Ve/+hWzZ8/OIPrilc8WxAhgsbt/4u5bgenAWfXUHwc8Gr4+FZjl7mvcfS0wCxiVx1hFpBkbN24c06dPr1U2ffr0lBPmJXv22WfZe++9szp2coK44YYbOPnkk7PaV7HJ52mufYBlkeXlBC2COsysPzAAeLGebfvEbDcRmAjQLx8zfYlIxi6/HMJbM+TMkCFw++2p159zzjlce+21bN26lfbt27NkyRI+//xzjjvuOCZNmsScOXPYtGkT55xzDr/+9a/rbF9WVkZVVRU9e/ZkypQpPPTQQ/Tu3Zu+ffsyfPhwILjGobKykq1bt3LQQQcxdepU5s6dy4wZM3jllVe46aabeOqpp7jxxhs588wzOeecc3jhhRe48sor2b59O0cddRT33HMPHTp0oKysjPHjx/PMM8+wbds2nnjiCQ499NBaMS1ZsoTzzz+fb775BoA777xz102LbrnlFh5++GHatGnDaaedxs0338zixYu56KKLqK6upqSkhCeeeIIDDzywUZ97sQxSjwWedPcdmWzk7pXuXu7u5b169cpTaCJS7Lp3786IESN47rnngKD18I//+I+YGVOmTKGqqor58+fzyiuvMH/+/JT7eeutt5g+fTpz587l2WefZc6cObvWnX322cyZM4d58+Zx2GGHcd999zFy5EhGjx7Nb37zG+bOnVvrB3nz5s1MmDCBxx57jHfffZft27dzzz337Frfs2dP3n77bSZNmhTbjZWYFvztt9/mscce23XXu+i04PPmzeOqq64CgmnBL7nkEubNm8frr7/Ofvvt17gPlfy2IFYAfSPLpWFZnLHAJUnbnpC07cs5jE1E8qS+v/TzKdHNdNZZZzF9+nTuu+8+AB5//HEqKyvZvn07X3zxBQsXLuTII4+M3cdrr73GmDFjdk25PXr06F3rFixYwLXXXsu6devYuHEjp556ar3xLFq0iAEDBnDwwQcDMH78eO666y4uv/xyIEg4AMOHD+cPf/hDne2LYVrwfLYg5gADzWyAmbUnSAIzkiuZ2aFAN+BvkeKZwClm1i0cnD4lLMu5XN8bV0QK46yzzuKFF17g7bffpqamhuHDh/Ppp59y66238sILLzB//nzOOOOMlNN8N2TChAnceeedvPvuu1x33XVZ7ychMWV4qunCi2Fa8LwlCHffDlxK8MP+PvC4u79nZjeY2ehI1bHAdI/MGujua4AbCZLMHOCGsCynEvfGXboU3HffG1dJQqT56dy5MyeeeCIXXHDBrsHpr7/+mj333JOuXbuyatWqXV1QqRx//PE8/fTTbNq0iQ0bNvDMM8/sWrdhwwb2228/tm3bxrTIj0SXLl3YsGFDnX0dcsghLFmyhMWLFwPBrKzf+c530n4/xTAteF7HINz9WXc/2N0PdPcpYdmv3H1GpM717l7nGgl3v9/dDwofD+Qjvqa6N66INI1x48Yxb968XQli8ODBDB06lEMPPZTzzjuPY489tt7thw0bxg9+8AMGDx7MaaedxlFHHbVr3Y033sjRRx/NscceW2tAeezYsfzmN79h6NChte4X3bFjRx544AHOPfdcjjjiCNq0acNFF12U9nsphmnBW/V0323aBC2HZGbBPPUikh5N9908aLrvDKQ6M1ZnzIqItPIE0ZT3xhURaW5adYIo1L1xRVqiltJd3VJl8/20+hsGVVQoIYg0VseOHVm9ejU9evTAzAodjiRxd1avXp3x9RGtPkGISOOVlpayfPlyqqurCx2KpNCxY0dKS0sz2kYJQkQarV27dgwYMKDQYUiOteoxCBERSU0JQkREYilBiIhIrBZzJbWZVQNLG7GLnsBXOQonXxRjbijG3FCMuVPIOPu7e+z9ElpMgmgsM6tKdbl5sVCMuaEYc0Mx5k6xxqkuJhERiaUEISIisZQgdqssdABpUIy5oRhzQzHmTlHGqTEIERGJpRaEiIjEUoIQEZFYrT5BmNkoM1tkZovNrM6tTwvFzO43sy/NbEGkrLuZzTKzj8LnbgWMr6+ZvWRmC83sPTP7WbHFGMbT0czeNLN5YZy/DssHmNkb4ff+mJm1L3CcJWb2jpn9qRjjC2NaYmbvmtlcM6sKy4rt+97bzJ40sw/M7H0zO6aYYjSzQ8LPL/H42swuL6YYo1p1gjCzEuAu4DRgEDDOzAYVNqpdHgRGJZVdDbzg7gOBF8LlQtkO/Iu7DwK+BVwSfnbFFCPAFuC77j4YGAKMMrNvAbcAt7n7QcBa4MeFCxGAnwHvR5aLLb6EE919SOSc/WL7vv8T+LO7HwoMJvhMiyZGd18Ufn5DgOFADfDHYoqxFndvtQ/gGGBmZPka4JpCxxWJpwxYEFleBOwXvt4PWFToGCOx/TfwvSKPsRPwNnA0wVWrbeP+HRQgrlKCH4XvAn8CrJjii8S5BOiZVFY03zfQFfiU8OSbYowxKa5TgL8Wc4ytugUB9AGWRZaXh2XFah93/yJ8vRLYp5DBJJhZGTAUeIMijDHsvpkLfAnMAj4G1rn79rBKob/324GrgJ3hcg+KK74EB543s7fMbGJYVkzf9wCgGngg7K77f2a2J8UVY9RY4NHwdVHG2NoTRLPlwZ8aBT9H2cw6A08Bl7v719F1xRKju+/woElfCowADi1sRLuZ2ZnAl+7+VqFjScO33X0YQZfsJWZ2fHRlEXzfbYFhwD3uPhT4hqSumiKIEYBwTGk08ETyumKJEZQgVgB9I8ulYVmxWmVm+wGEz18WMhgza0eQHKa5+x/C4qKKMcrd1wEvEXTZ7G1miRtmFfJ7PxYYbWZLgOkE3Uz/SfHEt4u7rwifvyToNx9BcX3fy4Hl7v5GuPwkQcIophgTTgPedvdV4XIxxtjqE8QcYGB4xkh7gibfjALHVJ8ZwPjw9XiCfv+CsODGw/cB77v7f0RWFU2MAGbWy8z2Dl/vQTBO8j5BojgnrFawON39Gncvdfcygn9/L7p7RbHEl2Bme5pZl8Rrgv7zBRTR9+3uK4FlZnZIWHQSsJAiijFiHLu7l6A4Y2zdg9RBS47TgQ8J+qUnFzqeSFyPAl8A2wj+MvoxQd/0C8BHwGygewHj+zZBM3g+MDd8nF5MMYZxHgm8E8a5APhVWH4A8CawmKCZ36EIvvMTgD8VY3xhPPPCx3uJ/ytF+H0PAarC7/tpoFsRxrgnsBroGikrqhgTD021ISIisVp7F5OIiKSgBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIg0wsx1JM3DmbCI1MyuLztgrUkzaNlxFpNXb5MFUHSKtiloQIlkK74/wb+E9Et40s4PC8jIze9HM5pvZC2bWLyzfx8z+GN6bYp6ZjQx3VWJm94b3q3g+vOIbM7vMgvttzDez6QV6m9KKKUGINGyPpC6mH0TWrXf3I4A7CWZlBfgv4CF3PxKYBtwRlt8BvOLBvSmGEVyRDDAQuMvdDwfWAf8rLL8aGBru56L8vDWR1HQltUgDzGyju3eOKV9CcDOiT8KJC1e6ew8z+4pgbv9tYfkX7t7TzKqBUnffEtlHGTDLgxvFYGb/CrRz95vM7M/ARoIpI5529415fqsitagFIdI4nuJ1JrZEXu9g99jgGQR3PBwGzInM7irSJJQgRBrnB5Hnv4WvXyeYmRWgAngtfP0CMAl23cSoa6qdmlkboK+7vwT8K8Hd0uq0YkTySX+RiDRsj/COdAl/dvfEqa7dzGw+QStgXFj2U4K7mv2c4A5nPwrLfwZUmtmPCVoKkwhm7I1TAjwcJhED7vDgfhYiTUZjECJZCscgyt39q0LHIpIP6mISEZFYakGIiEgstSBERCSWEoSIiMRSghARkVhKECIiEksJQkREYv1/L+lb8cTSAIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Step\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3265523910522461, 0.9357143044471741]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[47,  8],\n",
       "       [ 1, 84]])>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It will evaluate the logical expression y_predict>0.25 and return True or False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
